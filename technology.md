# Technologies projected to use
## Data Cleaning and Analysis
**Python** `Pandas` library will be used to *clean*, *prepare* and *explore* the data and perform the initial analysis;<br>
potentially to fill in/ drop any NaN data, remove redundant columns, create binning, etc.

## Database Storage
**Postgres** is the database we intend to use for storing the data.

## Machine Learning
`SciKitLearn` and `Tensorflow` are the **Mechine Learning** libraries we'll be using. 
The process is to 
1. use **One-Hot Encoder** to understand and evaluate any categorical variables,
2. split our preprocessed data into features and target arrays, and then the training and testing dataset,
3. scale the data,
4. perform either **Logic Regression**, **Support Vector Machine (SVM)**, or **Random Forest**,
5. compare with **Basic Neural Network (1 hidden layer)**, and **Deep Learning Model Design (2 hidden layers)**

## Dashboard
We will utilize **Tableau** for our dashboard to create visuals for data storytelling. 
It will be hosted on *Tableau Public*. 
